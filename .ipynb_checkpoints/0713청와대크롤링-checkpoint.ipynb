{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fitted-purple",
   "metadata": {},
   "source": [
    "# 연습문제\n",
    "\n",
    "2. 청와대 국민 청원 게시판에 있는 다양한 청원들의 “전체 목록” 에서 각 청원에 대한 상세 내역을 수집하는 웹 크롤러를 만드세요. 수집된 데이터 형식은 다음 페이지에 있는 각 형식별 수집 예시를 참고하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decreased-marketplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "청와대 국민 청원 게시판에 있는 다양한 청원들의 “전체 목록” 에서 각 청원에 대한 상세 내역을 수집\n",
      "====================================================================================================\n",
      "2.파일을 저장할 폴더명만 쓰세요(기본값:c:\\temp\\):\n",
      "크롤링할 건수 입력:4\n",
      "크롤링 할 총 페이지 번호:  1\n",
      "4 건의 데이터를 수집하기 위해 1 페이지의 게시물을 조회합니다.\n",
      "\n",
      "\n",
      "1 번째 페이지까지 4건 정보 수집 완료 ====================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1 번째 국민청원 게시글 상세 정보입니다==========================\n",
      "['https:', '', 'www1.president.go.kr', 'petitions', '599809']\n",
      "\n",
      "\n",
      "2 번째 국민청원 게시글 상세 정보입니다==========================\n",
      "['https:', '', 'www1.president.go.kr', 'petitions', '599808']\n",
      "\n",
      "\n",
      "3 번째 국민청원 게시글 상세 정보입니다==========================\n",
      "['https:', '', 'www1.president.go.kr', 'petitions', '599807']\n",
      "\n",
      "\n",
      "4 번째 국민청원 게시글 상세 정보입니다==========================\n",
      "['https:', '', 'www1.president.go.kr', 'petitions', '599806']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-75b4eb6ae8e6>:158: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  blue_house['청원제목'] = pd.Series(title2)\n",
      "<ipython-input-2-75b4eb6ae8e6>:159: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  blue_house['참여자'] = pd.Series(people2)\n",
      "<ipython-input-2-75b4eb6ae8e6>:160: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  blue_house['카테고리'] = pd.Series(category2)\n",
      "<ipython-input-2-75b4eb6ae8e6>:161: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  blue_house['청원시작일'] = pd.Series(s_date2)\n",
      "<ipython-input-2-75b4eb6ae8e6>:162: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  blue_house['청원종료일'] = pd.Series(e_date2)\n",
      "<ipython-input-2-75b4eb6ae8e6>:163: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  blue_house['청원내용'] = pd.Series(content2)\n",
      "<ipython-input-2-75b4eb6ae8e6>:169: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  blue_house.to_excel(fx_name , index=False)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time \n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\" *100)\n",
    "print(\"청와대 국민 청원 게시판에 있는 다양한 청원들의 “전체 목록” 에서 각 청원에 대한 상세 내역을 수집\")\n",
    "print(\"=\" *100)\n",
    "\n",
    "f_dir = input(\"2.파일을 저장할 폴더명만 쓰세요(기본값:c:\\\\temp\\\\):\")\n",
    "if f_dir == '' :\n",
    "    f_dir=\"c:\\\\temp\\\\\"\n",
    "# 저장될 파일위치와 이름을 지정합니다\n",
    "\n",
    "now = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)\n",
    "\n",
    "query_txt = '청와대국민청원'\n",
    "os.makedirs(f_dir+s+'-'+query_txt)\n",
    "os.chdir(f_dir+s+'-'+query_txt)\n",
    "\n",
    "ff_name=f_dir+s+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.txt'\n",
    "fc_name=f_dir+s+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.csv'\n",
    "fx_name=f_dir+s+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.xls'\n",
    "\n",
    "\n",
    "chrome_path = \"c:/temp/chromedriver_85/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "url = 'https://www1.president.go.kr/petitions'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "\n",
    "cnt = int(input('크롤링할 건수 입력:'))\n",
    "page_cnt = math.ceil(cnt/7)\n",
    "print('크롤링 할 총 페이지 번호: ', page_cnt)\n",
    "print('%s 건의 데이터를 수집하기 위해 %s 페이지의 게시물을 조회합니다.' %(cnt, page_cnt))\n",
    "print(\"\\n\")\n",
    "\n",
    "# url을 따와야 함\n",
    "url_list = []\n",
    "count = 0\n",
    "\n",
    "for i in range(1, page_cnt+1):\n",
    "    html_url = driver.page_source\n",
    "    soup_url = BeautifulSoup(html_url, 'html.parser')\n",
    "    \n",
    "    url1 = soup_url.find_all('div', 'board text')\n",
    "    url2 = url1[2].find('div', 'b_list category b_list2')\n",
    "    url3 = url2.find('div', 'bl_body').find('ul', 'petition_list').find_all('li')\n",
    "    \n",
    "    for j in url3:\n",
    "        url_ = j.find('a')['href']\n",
    "        full_url = 'https://www1.president.go.kr'+url_\n",
    "        url_list.append(full_url)\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "        if count == cnt :\n",
    "            break\n",
    "            \n",
    "    print(\"%s 번째 페이지까지 %s건 정보 수집 완료 ====================\" %(i,count))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    i += 1\n",
    "    try:\n",
    "        driver.find_element_by_link_text('%s' %i).click()\n",
    "    except:\n",
    "        driver.find_element_by_link_text('Next').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "no = 1\n",
    "\n",
    "cno2=[]\n",
    "title2=[]\n",
    "people2=[]\n",
    "category2=[]\n",
    "s_date2=[]\n",
    "e_date2=[]\n",
    "content2=[]\n",
    "\n",
    "for i in range(0,len(url_list)):  \n",
    "            \n",
    "    print(\"\\n\")\n",
    "    print(\"%s 번째 국민청원 게시글 상세 정보입니다==========================\" %no)\n",
    "    no += 1\n",
    "    driver.get(url_list[i])\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser') # 저장한 url 원소의 html 파싱 정보를 가져옴\n",
    "\n",
    "    content_all = soup.find('div','petitionsView_left_pg')\n",
    "    \n",
    "    f = open(ff_name, 'a',encoding='UTF-8')\n",
    "\n",
    "    # 청원 등록 번호\n",
    "    c_no = url_list[i].split('/')\n",
    "    print(c_no)\n",
    "    #cno_1 = c_no[4].split('?')\n",
    "    cno_1 = c_no[4]        \n",
    "    print('1.청원글번호: ',cno_1 ,'\\n')\n",
    "    f.write('\\n')\n",
    "    f.write(\"%s 번째 국민청원 게시글 상세 정보입니다==========================\" %no + '\\n')\n",
    "    f.write('1.청원번호:' + cno_1 + '\\n')\n",
    "    cno2.append(cno_1)\n",
    "\n",
    "    # 청원제목 추출\n",
    "    title = content_all.find('h3','petitionsView_title').get_text()\n",
    "    print('2.청원제목: ' , title , '\\n')\n",
    "    f.write('2.청원제목:' + title + '\\n')\n",
    "    title2.append(title)\n",
    "\n",
    "    # 참여인원 추출\n",
    "    people = content_all.find('h2','petitionsView_count').find('span','counter').get_text()\n",
    "    print('3.참여인원: ' , people ,'명' ,'\\n')\n",
    "    f.write('3.참여인원:' + people + '\\n')\n",
    "    people2.append(people)\n",
    "\n",
    "    # 카테고리\n",
    "    cat_all = content_all.find('div','petitionsView_info').find('ul','petitionsView_info_list').find_all('li')\n",
    "\n",
    "    category = cat_all[0].get_text().replace('카테고리','')\n",
    "    print('4.카테고리: ',category ,'\\n')\n",
    "    f.write('4.카테고리:' + category + '\\n')\n",
    "    category2.append(category)\n",
    "\n",
    "    # 청원시작일\n",
    "    s_date = cat_all[1].get_text().replace('청원시작','')\n",
    "    print('5.청원시작일: ',s_date ,'\\n')\n",
    "    f.write('5.청원시작일:' + s_date + '\\n')\n",
    "    s_date2.append(s_date)\n",
    "\n",
    "    # 청원마감일\n",
    "    e_date = cat_all[2].get_text().replace('청원마감','')\n",
    "    print('6.청원마감일: ',e_date ,'\\n')\n",
    "    f.write('6.청원종료일:' + e_date + '\\n')\n",
    "    e_date2.append(e_date)\n",
    "\n",
    "    # 청원내용\n",
    "    content = content_all.find('div','View_write').get_text().replace('\\n','')\n",
    "    print('7.청원내용: ', content.strip() , '\\n')\n",
    "    f.write('7.청원내용:' + content.strip() + '\\n')\n",
    "    content2.append(content)\n",
    "\n",
    "    f.close( )\n",
    "    \n",
    "    # Step 6. 출력 결과를 저장하기\n",
    "# 출력 결과를 표(데이터 프레임) 형태로 만들기\n",
    "\n",
    "blue_house = pd.DataFrame()\n",
    "\n",
    "blue_house['청원번호'] = cno2\n",
    "blue_house['청원제목'] = pd.Series(title2) \n",
    "blue_house['참여자'] = pd.Series(people2)\n",
    "blue_house['카테고리'] = pd.Series(category2)\n",
    "blue_house['청원시작일'] = pd.Series(s_date2)\n",
    "blue_house['청원종료일'] = pd.Series(e_date2)\n",
    "blue_house['청원내용'] = pd.Series(content2)\n",
    "       \n",
    "# csv 형태로 저장하기\n",
    "blue_house.to_csv(fc_name,encoding=\"utf-8-sig\",index=False)\n",
    "\n",
    "# 엑셀 형태로 저장하기\n",
    "blue_house.to_excel(fx_name , index=False)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "logical-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www1.president.go.kr/petitions/599809\n"
     ]
    }
   ],
   "source": [
    "driver.get(url_list[0])\n",
    "html_url = driver.page_source\n",
    "soup_url = BeautifulSoup(html_url, 'html.parser')\n",
    "\n",
    "print(url_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-chick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
