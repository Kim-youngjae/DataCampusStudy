{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "graphic-video",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 이 크롤러는 RISS 사이트의 논문 및 학술자료 수집용 웹크롤러입니다.\n",
      "====================================================================================================\n",
      "1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): 서진수 빅데이터\n",
      "2.결과를 저장할 txt형식의 파일명을 쓰세요(예: c:\\temp\\riss.txt): c:\\temp\\naver.txt\n",
      "3.결과를 저장할 csv형식의 파일명을 쓰세요(예: c:\\temp\\riss.csv): c:\\temp\\naver.csv\n",
      "4.결과를 저장할 xls형식의 파일명을 쓰세요(예: c:\\temp\\riss.xls): c:\\temp\\naver.xls\n"
     ]
    }
   ],
   "source": [
    "# riss.kr 에서 특정 키워드로 논문 / 학술 자료 검색하기\n",
    "\n",
    "#Step 1. 필요한 모듈을 로딩합니다\n",
    "from selenium import webdriver\n",
    "import time \n",
    "\n",
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 이 크롤러는 naver 사이트의 자료 수집용 웹크롤러입니다.\")\n",
    "print(\"=\" *100)\n",
    "query_txt = input('1.수집할 자료의 키워드는 무엇입니까?(여러개일 경우 , 로 구분하여 입력): ')\n",
    "\n",
    "#Step 3. 수집된 데이터를 저장할 파일 이름 입력받기 \n",
    "fc_name = input('3.결과를 저장할 csv형식의 파일명을 쓰세요(예: c:\\\\temp\\\\naver.csv): ')\n",
    "fx_name = input('4.결과를 저장할 xls형식의 파일명을 쓰세요(예: c:\\\\temp\\\\naver.xls): ')\n",
    "\n",
    "#Step 4. 크롬 드라이버 설정 및 웹 페이지 열기\n",
    "chrome_path = \"c:/temp/chromedriver_85/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "url = 'https://www.naver.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "driver.maximize_window()\n",
    "\n",
    "#Step 5. 자동으로 검색어 입력 후 조회하기\n",
    "element = driver.find_element_by_id(\"query\")\n",
    "driver.find_element_by_id(\"query\").click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "time.sleep(2)\n",
    "\n",
    "#Step 6.학위 논문 선택하기\n",
    "driver.find_element_by_link_text('VIEW').click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Step 7.Beautiful Soup 로 본문 내용만 추출하기\n",
    "from bs4 import BeautifulSoup\n",
    "html_1 = driver.page_source\n",
    "soup_1 = BeautifulSoup(html_1, 'html.parser')\n",
    "\n",
    "content_1 = soup_1.find('div','srchResultListW').find_all('li')\n",
    "for i in content_1 :\n",
    "    print(i.get_text().replace(\"\\n\",\"\"))\n",
    "\n",
    "#Step 8. 총 검색 건수를 보여주고 수집할 건수 입력받기\n",
    "import math\n",
    "total_cnt = soup_1.find('div','searchBox pd').find('span','num').get_text()\n",
    "print('검색하신 키워드 %s (으)로 총 %s 건의 학위논문이 검색되었습니다' %(query_txt,total_cnt))\n",
    "collect_cnt = int(input('이 중에서 몇 건을 수집하시겠습니까?: '))\n",
    "collect_page_cnt = math.ceil(collect_cnt / 10)\n",
    "print('%s 건의 데이터를 수집하기 위해 %s 페이지의 게시물을 조회합니다.' %(collect_cnt,collect_page_cnt))\n",
    "\n",
    "#Step 9. 각 항목별로 데이터를 추출하여 리스트에 저장하기\n",
    "no2 = [ ]        #번호 저장\n",
    "title2 = [ ]     #논문제목 저장\n",
    "writer2 = [ ]    #논문저자 저장\n",
    "org2 = [ ]       #소속기관 저장\n",
    "no = 1\n",
    "\n",
    "# 다음 페이지 번호 만들기\n",
    "page_no=[ ]\n",
    "\n",
    "for i in range(10,collect_cnt) :\n",
    "    if i % 10 == 0 :\n",
    "            page_no.append(i + 1)\n",
    "\n",
    "for a in range(1, collect_page_cnt + 1) :\n",
    "    \n",
    "    html_2 = driver.page_source\n",
    "    soup_2 = BeautifulSoup(html_2, 'html.parser')\n",
    "\n",
    "    content_2 = soup_2.find('div','srchResultListW').find_all('li')\n",
    "    \n",
    "    for b in content_2 :    \n",
    "        #1. 논문제목 있을 경우만\n",
    "        try :\n",
    "            title = b.find('div','cont').find('p','title').get_text()\n",
    "        except :\n",
    "            continue\n",
    "        else :\n",
    "            f = open(ft_name, 'a' , encoding=\"UTF-8\")\n",
    "            print('1.번호:',no)\n",
    "            no2.append(no)\n",
    "            f.write('\\n'+'1.번호:' + str(no))\n",
    "\n",
    "            print('2.논문제목:',title)\n",
    "            title2.append(title)\n",
    "            f.write('\\n' + '2.논문제목:' + title)\n",
    "            \n",
    "            writer = b.find('span','writer').get_text()\n",
    "            print('3.저자:',writer)\n",
    "            writer2.append(writer)\n",
    "            f.write('\\n' + '3.저자:' + writer)\n",
    "\n",
    "            org = b.find('span','assigned').get_text()\n",
    "            print('4.소속기관:' , org)\n",
    "            org2.append(org)\n",
    "            f.write('\\n' + '4.소속기관:' + org + '\\n')\n",
    "            \n",
    "            f.close( )\n",
    "            \n",
    "            no += 1\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            if no > collect_cnt :\n",
    "                break\n",
    "\n",
    "            time.sleep(1)        # 페이지 변경 전 1초 대기 \n",
    "\n",
    "#         c = math.floor(a/10)-1 \n",
    "        a += 1\n",
    "\n",
    "#         if a == page_no[c]:\n",
    "#             driver.find_element_by_link_text('다음 페이지로').click()\n",
    "#         else :\n",
    "#             driver.find_element_by_link_text('%s' %a).click() # 다음 페이지번호 클릭       \n",
    "    \n",
    "        try:\n",
    "            driver.find_element_by_link_text('%s', %a).click()\n",
    "        except:\n",
    "            driver.find_element_by_link_text('다음 페이지로').click()\n",
    "            \n",
    "print(\"요청하신 작업이 모두 완료되었습니다\")\n",
    "\n",
    "# Step 10. 수집된 데이터를 xls와 csv 형태로 저장하기\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['번호']=no2\n",
    "df['제목']=pd.Series(title2)\n",
    "df['저자']=pd.Series(writer2)\n",
    "df['소속(발행)기관']=pd.Series(org2)\n",
    "\n",
    "# xls 형태로 저장하기\n",
    "df.to_excel(fx_name,index=False, encoding=\"utf-8\")\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "df.to_csv(fc_name,index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print('요청하신 데이터 수집 작업이 정상적으로 완료되었습니다')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
